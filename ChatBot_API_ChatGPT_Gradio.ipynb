{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXJ4lwEXLAkd",
        "outputId": "5646fcc4-a9af-4d98-dee3-ffafe4a061d8"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y pydantic\n",
        "!pip install pydantic==1.10.7\n",
        "!pip install langchain --upgrade\n",
        "!pip install langchain_community\n",
        "!pip install openai\n",
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uKrxLTMLwq_"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import ChatMessage\n",
        "\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N7vY_PnN55Q"
      },
      "outputs": [],
      "source": [
        "# Função para carregar as informações da pizzaria de um arquivo JSON\n",
        "def carregar_informacoes_pizzaria():\n",
        "    with open('config_pizzaria.json', 'r', encoding='utf-8') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "def carregar_template_contexto():\n",
        "    with open('context_template.txt', 'r', encoding='utf-8') as file:\n",
        "        return file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W7DiDgDOR2G"
      },
      "outputs": [],
      "source": [
        "# Função para carregar o contexto com informações dinâmicas\n",
        "def getContexto():\n",
        "    info = carregar_informacoes_pizzaria()\n",
        "    template_contexto = carregar_template_contexto()\n",
        "    cardapio_str = ', '.join(info['cardapio'].keys())\n",
        "\n",
        "    contexto = template_contexto.format(\n",
        "        nome=info['nome'],\n",
        "        endereco=info['endereco'],\n",
        "        horario_funcionamento=info['horario_funcionamento'],\n",
        "        telefone=info['telefone'],\n",
        "        email=info['email'],\n",
        "        site=info['site'],\n",
        "        cardapio=cardapio_str,\n",
        "        promocoes=info['promocoes'],\n",
        "        forma_pagamento=\", \".join(info['forma_pagamento']),\n",
        "        taxa_entrega=info['taxa_entrega']\n",
        "    )\n",
        "\n",
        "    return contexto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY9YGC9hUyXM"
      },
      "outputs": [],
      "source": [
        "#Função para inicializar o histórico de mensagens\n",
        "def start_chat(openai_api_key):\n",
        "    if not openai_api_key:\n",
        "        return [], \"Por favor, insira sua chave da API.\"\n",
        "\n",
        "    # Inicializa as mensagens com uma mensagem do assistente\n",
        "    messages = [(\"assistant\", \"Fala, beleza? Como posso te ajudar? Pergunte sobre nossa pizzaria!\")]\n",
        "    return messages, \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-njpV52lZDa4"
      },
      "outputs": [],
      "source": [
        "contexto = getContexto()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03fekP6iay8H"
      },
      "outputs": [],
      "source": [
        "# Função para gerar a resposta do chatbot com contexto da pizzaria\n",
        "def chatbot_response(messages, user_input, openai_api_key, model=\"gpt-3.5-turbo\", temperature=0.3, max_tokens=250):\n",
        "    try:\n",
        "        if not openai_api_key:\n",
        "            return messages, \"\", \"Por favor, insira a chave da API.\"\n",
        "\n",
        "        # Inicializa o modelo de linguagem com a chave da API da OpenAI e parâmetros personalizados\n",
        "        llm = ChatOpenAI(\n",
        "            openai_api_key=openai_api_key,\n",
        "            model=model,          # Define o modelo\n",
        "            temperature=temperature,  # Define a temperatura\n",
        "            max_tokens=max_tokens     # Define o número máximo de tokens\n",
        "        )\n",
        "\n",
        "        # Adiciona a mensagem do usuário ao histórico\n",
        "        messages.append((\"user\", user_input))\n",
        "\n",
        "       # Converte as mensagens para o formato esperado e adiciona o contexto\n",
        "        conversation = [ChatMessage(role=\"system\", content=contexto)] + [ChatMessage(role=msg[0], content=msg[1]) for msg in messages]\n",
        "\n",
        "        # Gera a resposta\n",
        "        response = llm(conversation)\n",
        "\n",
        "        # Adiciona a resposta do assistente ao histórico\n",
        "        messages.append((\"assistant\", response.content))\n",
        "\n",
        "        return messages, \"\", \"\"  # Retorna as mensagens atualizadas e limpa o input\n",
        "    except Exception as e:\n",
        "        return messages, \"\", f\"Erro: {str(e)}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGb3bbgYa6wN"
      },
      "outputs": [],
      "source": [
        "# Função para inicializar o histórico de mensagens\n",
        "def start_chat(openai_api_key):\n",
        "    if not openai_api_key:\n",
        "        return [], \"Por favor, insira sua chave da API.\"\n",
        "\n",
        "    # Inicializa as mensagens com uma mensagem do assistente\n",
        "    messages = [(\"assistant\", \"Seja bem-vindo à Pizzaria BOT. Como posso te ajudar?\")]\n",
        "    return messages, \"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "H44bxte_a9Sw",
        "outputId": "e7120c89-b853-4d4e-f22a-34c20fa38033"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Interface Gradio\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Chatbot da Pizzaria BOT usando OpenAI API e Gradio\")\n",
        "\n",
        "    # Campo para inserção da chave da API da OpenAI\n",
        "    openai_api_key = gr.Textbox(label=\"Chave da API da OpenAI\", type=\"password\")\n",
        "\n",
        "    # Caixa de chat exibindo as mensagens\n",
        "    chatbox = gr.Chatbot(label=\"Chatbot\")\n",
        "\n",
        "    # Entrada do usuário\n",
        "    user_input = gr.Textbox(label=\"Sua mensagem\", interactive=False)\n",
        "\n",
        "    # Entrada para o modelo\n",
        "    model_input = gr.Textbox(label=\"Modelo OpenAI\", value=\"gpt-3.5-turbo\", interactive=True)\n",
        "\n",
        "    # Entrada para a temperatura\n",
        "    temperature_input = gr.Slider(label=\"Temperatura\", minimum=0, maximum=1, value=0.3)\n",
        "\n",
        "    # Entrada para o número máximo de tokens\n",
        "    max_tokens_input = gr.Number(label=\"Máximo de Tokens\", value=250)\n",
        "\n",
        "    # Mensagem de erro (se houver)\n",
        "    error_output = gr.Markdown()\n",
        "\n",
        "    # Botão para iniciar a conversa\n",
        "    btn_start = gr.Button(\"Iniciar Chat\")\n",
        "\n",
        "    # Função de clique do botão \"Iniciar Chat\"\n",
        "    btn_start.click(\n",
        "        start_chat,\n",
        "        inputs=openai_api_key,\n",
        "        outputs=[chatbox, error_output],\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    # Atualiza a caixa de chat quando o usuário envia uma nova mensagem\n",
        "    user_input.submit(\n",
        "        chatbot_response,\n",
        "        inputs=[chatbox, user_input, openai_api_key, model_input, temperature_input, max_tokens_input],\n",
        "        outputs=[chatbox, user_input, error_output],\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    # Ativa o campo de entrada de texto quando a chave da API for fornecida\n",
        "    openai_api_key.change(\n",
        "        lambda key: gr.update(interactive=bool(key)),\n",
        "        inputs=openai_api_key,\n",
        "        outputs=user_input\n",
        "    )\n",
        "\n",
        "# Lança a interface\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
